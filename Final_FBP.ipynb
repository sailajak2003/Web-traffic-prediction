{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_FBP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDKcH4TNn_G1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install pyspark\n",
        "# !pip3 install pystan\n",
        "# !pip3 install fbprophet\n",
        "# !sudo apt install openjdk-8-jdk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifze7faEtgHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "java8_location= '/usr/lib/jvm/java-8-openjdk-amd64' # Set your own\n",
        "os.environ['JAVA_HOME'] = java8_location "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2FGa3K5nw2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSvGo486tgKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fbprophet import Prophet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zsw3nK9ZobR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import array, col, explode, lit, struct\n",
        "from pyspark.sql import DataFrame\n",
        "from typing import Iterable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R29zeAHbgjY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.functions import (dayofmonth,hour,dayofyear,month,year,\n",
        "                              weekofyear,format_number,date_format,to_date)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Upj-YzFeooBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql import functions as F\n",
        "spark = SparkSession.builder.appName('Final').config(\"spark.driver.memory\", \"20g\").config(\"spark.executor.memory\",\"20g\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-_0fBmqk3sX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sc = spark.sparkContext"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgzbCiuuym3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import SQLContext\n",
        "sqlContext = SQLContext(sc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N77JsTh3oqzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #small5000 = spark.read.csv('/content/drive/My Drive/small_5000.csv',inferSchema=True,header=True)\n",
        "small5000 = spark.read.csv('/content/drive/My Drive/Project4/train_1.csv',inferSchema=True, header=True)\n",
        "# small5000 = spark.read.csv('/content/drive/My Drive/top20p.csv',inferSchema=True,header=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGcU3P-xgFyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dates_cols = small5000.drop('_c0','Page').columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqt-FRBTUm3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://stackoverflow.com/questions/41670103/how-to-melt-spark-dataframe\n",
        "#Thanks a lot for the Melt Function in spark\n",
        "\n",
        "def melt(\n",
        "        df: DataFrame, \n",
        "        id_vars: Iterable[str], value_vars: Iterable[str], \n",
        "        var_name: str=\"variable\", value_name: str=\"value\") -> DataFrame:\n",
        "    \"\"\"Convert :class:`DataFrame` from wide to long format.\"\"\"\n",
        "\n",
        "    # Create array<struct<variable: str, value: ...>>\n",
        "    _vars_and_vals = array(*(\n",
        "        struct(lit(c).alias(var_name), col(c).alias(value_name)) \n",
        "        for c in value_vars))\n",
        "\n",
        "    # Add to the DataFrame and explode\n",
        "    _tmp = df.withColumn(\"_vars_and_vals\", explode(_vars_and_vals))\n",
        "\n",
        "    cols = id_vars + [\n",
        "            col(\"_vars_and_vals\")[x].alias(x) for x in [var_name, value_name]]\n",
        "    return _tmp.select(*cols)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6evBRlipd0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train2 = melt(small5000,id_vars=['Page'], value_vars=dates_cols)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWe3t5M6pp4s",
        "colab_type": "code",
        "outputId": "b4d970ae-2584-41e2-a510-ab73de0022d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "train2.printSchema()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Page: string (nullable = true)\n",
            " |-- variable: string (nullable = false)\n",
            " |-- value: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8qXLyPW-BIgQ",
        "colab": {}
      },
      "source": [
        "#train3 = train2.withColumn('ds',to_date('variable')).drop('variable')\n",
        "train3 = train2.withColumn('value',train2['value'].cast('Integer'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCPTVIzlR_Gp",
        "colab_type": "code",
        "outputId": "16f1fd7e-521d-45ab-898e-df6b722b5cca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "train3.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Page='2NE1_zh.wikipedia.org_all-access_spider', variable='2015-07-01', value=18),\n",
              " Row(Page='2NE1_zh.wikipedia.org_all-access_spider', variable='2015-07-02', value=11),\n",
              " Row(Page='2NE1_zh.wikipedia.org_all-access_spider', variable='2015-07-03', value=5),\n",
              " Row(Page='2NE1_zh.wikipedia.org_all-access_spider', variable='2015-07-04', value=13),\n",
              " Row(Page='2NE1_zh.wikipedia.org_all-access_spider', variable='2015-07-05', value=14)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjgfF_SaOPVm",
        "colab_type": "code",
        "outputId": "2e7846ef-716a-45bf-d612-94d5429422c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "train3.groupBy('Page').count().show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------------+-----+\n",
            "|                          Page|count|\n",
            "+------------------------------+-----+\n",
            "|          EXID_zh.wikipedia...|  550|\n",
            "|       水菜麗_zh.wikipedia....|  550|\n",
            "|       朴炯植_zh.wikipedia....|  550|\n",
            "| 進擊的巨人角色列表_zh.wiki...|  550|\n",
            "|       陳庭妮_zh.wikipedia....|  550|\n",
            "|     太阳能电池_zh.wikipedi...|  550|\n",
            "|     成均馆大学_zh.wikipedi...|  550|\n",
            "|      賽菲羅斯_zh.wikipedia...|  550|\n",
            "|      中島美嘉_zh.wikipedia...|  550|\n",
            "|     湄公河大案_zh.wikipedi...|  550|\n",
            "|雲之彼端，約定的地方_zh.wik...|  550|\n",
            "|   罗斯柴尔德家族_zh.wikipe...|  550|\n",
            "|      長榮航空_zh.wikipedia...|  550|\n",
            "|      班淑傳奇_zh.wikipedia...|  550|\n",
            "|       黃義雄_zh.wikipedia....|  550|\n",
            "|    歡樂頌_(電視劇)_zh.wiki...|  550|\n",
            "|      星際過客_zh.wikipedia...|  550|\n",
            "|    2017無綫節目巡禮_zh.wik...|  550|\n",
            "|          Amazon.com_fr.wik...|  550|\n",
            "|          Championnat_d'Eur...|  550|\n",
            "+------------------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-ZOUj5Og51I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "result_schema =StructType([                      \n",
        "  StructField('Page',StringType()),\n",
        "  StructField('y',FloatType()),\n",
        "  StructField('ds',DateType()),\n",
        "  StructField('yhat',FloatType()),\n",
        "  StructField('yhat_upper',FloatType()),\n",
        "  StructField('yhat_lower',FloatType())\n",
        "  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzFK5pn7F0Gf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
        "\n",
        "@pandas_udf(result_schema,PandasUDFType.GROUPED_MAP)\n",
        "def forecast_page_views(sdf):\n",
        "  \n",
        "  sdf['value']=pd.to_numeric(sdf['value'],errors='coerce')\n",
        "  sdf.reset_index(inplace=True)\n",
        "  first = sdf.notna().idxmax()[2]\n",
        "  sdf = sdf[first:]\n",
        "\n",
        "  mean_value=sdf['value'].dropna().mean()\n",
        "  sdf['value'].fillna(value=mean_value)\n",
        "\n",
        "  sdf['cap'] = sdf['value'].max()*2\n",
        "  sdf['floor'] = 0 \n",
        "  #sdf.dropna()\n",
        "  sdf['ds']= pd.to_datetime(sdf['variable'],errors='coerce')\n",
        "  sdf['y'] = sdf['value']\n",
        "  \n",
        "  \n",
        "  model = Prophet(interval_width=0.90,growth='logistic', daily_seasonality=False, weekly_seasonality=False,yearly_seasonality=True,seasonality_mode='additive')\n",
        "  try:\n",
        "    # train the model\n",
        "    model.fit(sdf)\n",
        "    # make predictions\n",
        "    future_pd = model.make_future_dataframe(periods=90,freq='d',include_history=True)\n",
        "    future_pd['cap'] = sdf['value'].max()*2\n",
        "    future_pd['floor'] = 0\n",
        "\n",
        "    forecast_pd = model.predict(future_pd)  \n",
        "    f_pd = pd.concat([sdf[['Page','y']],forecast_pd[['ds','yhat', 'yhat_upper', 'yhat_lower']]],axis=1)\n",
        "    f_pd['Page']= sdf['Page'].iloc[0]\n",
        "    f_pd['yhat'] = f_pd['yhat'].apply(lambda x: x if x> 0 else 0)\n",
        "\n",
        "  except:\n",
        "    zeros = pd.DataFrame(np.zeros((len(sdf['ds']),3)))\n",
        "    f_pd = pd.concat([sdf['Page','y','ds'],zeros],axis=1)\n",
        "    f_pd.columns=['Page','y','ds','yhat', 'yhat_upper', 'yhat_lower']\n",
        "    \n",
        "  \n",
        "  del model, sdf, future_pd, forecast_pd\n",
        "  return f_pd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG0jYb8AF_Az",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#results = page_history.groupBy('Page','ds').apply(forecast_page_views)\n",
        "results = train2.groupBy('Page').apply(forecast_page_views)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAbO02Rllps6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J83Gdz12bZl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#results.write.csv('/content/drive/My Drive/Project4/train_1_results.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16QDscfpBdHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#rc = results.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1yNa3q6PG9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# results.write.format('com.databricks.spark.csv').save('/content/drive/My Drive/top20p_Results.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vUD-8ahoadF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# results.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjIK5iqbrhDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjHLZ1nyWF0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v31uFZLDam0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}